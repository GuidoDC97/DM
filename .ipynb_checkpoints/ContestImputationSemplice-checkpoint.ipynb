{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vqO4oT1pyC0d"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict, KFold, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import minmax_scale, StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import Constants as const\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_cJ3hI7yC07"
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCDGnR-HyC0-"
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_esito(df):\n",
    "    perc = 10/100\n",
    "    for i in range(df.shape[0]):\n",
    "        if df.loc[i,\"MMSE_PC\"] == df.loc[i,\"MMSE_PC\"]:\n",
    "            if df.loc[i,\"MMSE_PC\"] < const.const_dict[\"MMSE_CUTOFF\"] + const.const_dict[\"MMSE_CUTOFF\"]*perc and df.loc[i,\"MMSE_PC\"] > const.const_dict[\"MMSE_CUTOFF\"] - const.const_dict[\"MMSE_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"MMSE_ESITO\"] = \"LIMITI\"\n",
    "            elif df.loc[i,\"MMSE_PC\"] < const.const_dict[\"MMSE_CUTOFF\"] - const.const_dict[\"MMSE_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"MMSE_ESITO\"] = \"DEFICIT\"\n",
    "            else:\n",
    "                df.loc[i,\"MMSE_ESITO\"] = \"NORMA\"\n",
    "        if df.loc[i,\"MMSE_PG\"] == df.loc[i,\"MMSE_PG\"]:\n",
    "            if df.loc[i,\"MMSE_PG\"] < const.const_dict[\"MMSE_CUTOFF\"] + const.const_dict[\"MMSE_CUTOFF\"]*perc and df.loc[i,\"MMSE_PG\"] > const.const_dict[\"MMSE_CUTOFF\"] - const.const_dict[\"MMSE_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"MMSE_ESITO\"] = \"LIMITI\"\n",
    "            elif df.loc[i,\"MMSE_PG\"] < const.const_dict[\"MMSE_CUTOFF\"] - const.const_dict[\"MMSE_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"MMSE_ESITO\"] = \"DEFICIT\"\n",
    "            else:\n",
    "                df.loc[i,\"MMSE_ESITO\"] = \"NORMA\"\n",
    "        \n",
    "        \n",
    "        if df.loc[i,\"COPIAFIGURAREY_PC\"] == df.loc[i,\"COPIAFIGURAREY_PC\"]:\n",
    "            if df.loc[i,\"COPIAFIGURAREY_PC\"] < const.const_dict[\"COPIAFIGURAREY_CUTOFF\"] + const.const_dict[\"COPIAFIGURAREY_CUTOFF\"]*perc and df.loc[i,\"COPIAFIGURAREY_PC\"] > const.const_dict[\"COPIAFIGURAREY_CUTOFF\"] - const.const_dict[\"COPIAFIGURAREY_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"COPIAFIGURAREY_ESITO\"] = \"LIMITI\"\n",
    "            elif df.loc[i,\"COPIAFIGURAREY_PC\"] < const.const_dict[\"COPIAFIGURAREY_CUTOFF\"] - const.const_dict[\"COPIAFIGURAREY_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"COPIAFIGURAREY_ESITO\"] = \"DEFICIT\"\n",
    "            else:\n",
    "                df.loc[i,\"COPIAFIGURAREY_ESITO\"] = \"NORMA\"\n",
    "        if df.loc[i,\"COPIAFIGURAREY_PG\"] == df.loc[i,\"COPIAFIGURAREY_PG\"]:\n",
    "            if df.loc[i,\"COPIAFIGURAREY_PG\"] < const.const_dict[\"COPIAFIGURAREY_CUTOFF\"] + const.const_dict[\"COPIAFIGURAREY_CUTOFF\"]*perc and df.loc[i,\"COPIAFIGURAREY_PG\"] > const.const_dict[\"COPIAFIGURAREY_CUTOFF\"] - const.const_dict[\"COPIAFIGURAREY_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"COPIAFIGURAREY_ESITO\"] = \"LIMITI\"\n",
    "            elif df.loc[i,\"COPIAFIGURAREY_PG\"] < const.const_dict[\"COPIAFIGURAREY_CUTOFF\"] - const.const_dict[\"COPIAFIGURAREY_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"COPIAFIGURAREY_ESITO\"] = \"DEFICIT\"\n",
    "            else:\n",
    "                df.loc[i,\"COPIAFIGURAREY_ESITO\"] = \"NORMA\"\n",
    "                \n",
    "        \n",
    "        if df.loc[i,\"PAROLEREYIMM_PC\"] == df.loc[i,\"PAROLEREYIMM_PC\"]:\n",
    "            if df.loc[i,\"PAROLEREYIMM_PC\"] < const.const_dict[\"PAROLEREYIMM_CUTOFF\"] + const.const_dict[\"PAROLEREYIMM_CUTOFF\"]*perc and df.loc[i,\"PAROLEREYIMM_PC\"] > const.const_dict[\"PAROLEREYIMM_CUTOFF\"] - const.const_dict[\"PAROLEREYIMM_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"PAROLEREYIMM_ESITO\"] = \"LIMITI\"\n",
    "            elif df.loc[i,\"PAROLEREYIMM_PC\"] < const.const_dict[\"PAROLEREYIMM_CUTOFF\"] - const.const_dict[\"PAROLEREYIMM_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"PAROLEREYIMM_ESITO\"] = \"DEFICIT\"\n",
    "            else:\n",
    "                df.loc[i,\"PAROLEREYIMM_ESITO\"] = \"NORMA\"\n",
    "        if df.loc[i,\"PAROLEREYIMM_PG\"] == df.loc[i,\"PAROLEREYIMM_PG\"]:\n",
    "            if df.loc[i,\"PAROLEREYIMM_PG\"] < const.const_dict[\"PAROLEREYIMM_CUTOFF\"] + const.const_dict[\"PAROLEREYIMM_CUTOFF\"]*perc and df.loc[i,\"PAROLEREYIMM_PG\"] > const.const_dict[\"PAROLEREYIMM_CUTOFF\"] - const.const_dict[\"PAROLEREYIMM_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"PAROLEREYIMM_ESITO\"] = \"LIMITI\"\n",
    "            elif df.loc[i,\"PAROLEREYIMM_PG\"] < const.const_dict[\"PAROLEREYIMM_CUTOFF\"] - const.const_dict[\"PAROLEREYIMM_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"PAROLEREYIMM_ESITO\"] = \"DEFICIT\"\n",
    "            else:\n",
    "                df.loc[i,\"PAROLEREYIMM_ESITO\"] = \"NORMA\"\n",
    "        \n",
    "        \n",
    "        if df.loc[i,\"PAROLEREYDIFF_PC\"] == df.loc[i,\"PAROLEREYDIFF_PC\"]:\n",
    "            if df.loc[i,\"PAROLEREYDIFF_PC\"] < const.const_dict[\"PAROLEREYDIFF_CUTOFF\"] + const.const_dict[\"PAROLEREYDIFF_CUTOFF\"]*perc and df.loc[i,\"PAROLEREYDIFF_PC\"] > const.const_dict[\"PAROLEREYDIFF_CUTOFF\"] - const.const_dict[\"PAROLEREYDIFF_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"PAROLEREYDIFF_ESITO\"] = \"LIMITI\"\n",
    "            elif df.loc[i,\"PAROLEREYDIFF_PC\"] < const.const_dict[\"PAROLEREYDIFF_CUTOFF\"] - const.const_dict[\"PAROLEREYDIFF_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"PAROLEREYDIFF_ESITO\"] = \"DEFICIT\"\n",
    "            else:\n",
    "                df.loc[i,\"PAROLEREYDIFF_ESITO\"] = \"NORMA\"\n",
    "        if df.loc[i,\"PAROLEREYDIFF_PG\"] == df.loc[i,\"PAROLEREYDIFF_PG\"]:\n",
    "            if df.loc[i,\"PAROLEREYDIFF_PG\"] < const.const_dict[\"PAROLEREYDIFF_CUTOFF\"] + const.const_dict[\"PAROLEREYDIFF_CUTOFF\"]*perc and df.loc[i,\"PAROLEREYDIFF_PG\"] > const.const_dict[\"PAROLEREYDIFF_CUTOFF\"] - const.const_dict[\"PAROLEREYDIFF_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"PAROLEREYDIFF_ESITO\"] = \"LIMITI\"\n",
    "            elif df.loc[i,\"PAROLEREYDIFF_PG\"] < const.const_dict[\"PAROLEREYDIFF_CUTOFF\"] - const.const_dict[\"PAROLEREYDIFF_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"PAROLEREYDIFF_ESITO\"] = \"DEFICIT\"\n",
    "            else:\n",
    "                df.loc[i,\"PAROLEREYDIFF_ESITO\"] = \"NORMA\"\n",
    "        \n",
    "        \n",
    "        if df.loc[i,\"MEMORIAFIGURAREY_PC\"] == df.loc[i,\"MEMORIAFIGURAREY_PC\"]:\n",
    "            if df.loc[i,\"MEMORIAFIGURAREY_PC\"] < const.const_dict[\"MEMORIAFIGURAREY_CUTOFF\"] + const.const_dict[\"MEMORIAFIGURAREY_CUTOFF\"]*perc and df.loc[i,\"MEMORIAFIGURAREY_PC\"] > const.const_dict[\"MEMORIAFIGURAREY_CUTOFF\"] - const.const_dict[\"MEMORIAFIGURAREY_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"MEMORIAFIGURAREY_ESITO\"] = \"LIMITI\"\n",
    "            elif df.loc[i,\"MEMORIAFIGURAREY_PC\"] < const.const_dict[\"MEMORIAFIGURAREY_CUTOFF\"] - const.const_dict[\"MEMORIAFIGURAREY_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"MEMORIAFIGURAREY_ESITO\"] = \"DEFICIT\"\n",
    "            else:\n",
    "                df.loc[i,\"MEMORIAFIGURAREY_ESITO\"] = \"NORMA\"\n",
    "        if df.loc[i,\"MEMORIAFIGURAREY_PG\"] == df.loc[i,\"MEMORIAFIGURAREY_PG\"]:\n",
    "            if df.loc[i,\"MEMORIAFIGURAREY_PG\"] < const.const_dict[\"MEMORIAFIGURAREY_CUTOFF\"] + const.const_dict[\"MEMORIAFIGURAREY_CUTOFF\"]*perc and df.loc[i,\"MEMORIAFIGURAREY_PG\"] > const.const_dict[\"MEMORIAFIGURAREY_CUTOFF\"] - const.const_dict[\"MEMORIAFIGURAREY_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"MEMORIAFIGURAREY_ESITO\"] = \"LIMITI\"\n",
    "            elif df.loc[i,\"MEMORIAFIGURAREY_PG\"] < const.const_dict[\"MEMORIAFIGURAREY_CUTOFF\"] - const.const_dict[\"MEMORIAFIGURAREY_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"MEMORIAFIGURAREY_ESITO\"] = \"DEFICIT\"\n",
    "            else:\n",
    "                df.loc[i,\"MEMORIAFIGURAREY_ESITO\"] = \"NORMA\"\n",
    "        \n",
    "        \n",
    "        if df.loc[i,\"FAB_PC\"] == df.loc[i,\"FAB_PC\"]:\n",
    "            if df.loc[i,\"FAB_PC\"] < const.const_dict[\"FAB_CUTOFF\"] + const.const_dict[\"FAB_CUTOFF\"]*perc and df.loc[i,\"FAB_PC\"] > const.const_dict[\"FAB_CUTOFF\"] - const.const_dict[\"FAB_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"FAB_ESITO\"] = \"LIMITI\"\n",
    "            elif df.loc[i,\"FAB_PC\"] < const.const_dict[\"FAB_CUTOFF\"] - const.const_dict[\"FAB_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"FAB_ESITO\"] = \"DEFICIT\"\n",
    "            else:\n",
    "                df.loc[i,\"FAB_ESITO\"] = \"NORMA\"\n",
    "        if df.loc[i,\"FAB_PG\"] == df.loc[i,\"FAB_PG\"]:\n",
    "            if df.loc[i,\"FAB_PG\"] < const.const_dict[\"FAB_CUTOFF\"] + const.const_dict[\"FAB_CUTOFF\"]*perc and df.loc[i,\"FAB_PG\"] > const.const_dict[\"FAB_CUTOFF\"] - const.const_dict[\"FAB_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"FAB_ESITO\"] = \"LIMITI\"\n",
    "            elif df.loc[i,\"FAB_PG\"] < const.const_dict[\"FAB_CUTOFF\"] - const.const_dict[\"FAB_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"FAB_ESITO\"] = \"DEFICIT\"\n",
    "            else:\n",
    "                df.loc[i,\"FAB_ESITO\"] = \"NORMA\"\n",
    "        \n",
    "        \n",
    "        if df.loc[i,\"FLUENZAVERBFON_PC\"] == df.loc[i,\"FLUENZAVERBFON_PC\"]:\n",
    "            if df.loc[i,\"FLUENZAVERBFON_PC\"] < const.const_dict[\"FLUENZAVERBFON_CUTOFF\"] + const.const_dict[\"FLUENZAVERBFON_CUTOFF\"]*perc and df.loc[i,\"FLUENZAVERBFON_PC\"] > const.const_dict[\"FLUENZAVERBFON_CUTOFF\"] - const.const_dict[\"FLUENZAVERBFON_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"FLUENZAVERBFON_ESITO\"] = \"LIMITI\"\n",
    "            elif df.loc[i,\"FLUENZAVERBFON_PC\"] < const.const_dict[\"FLUENZAVERBFON_CUTOFF\"] - const.const_dict[\"FLUENZAVERBFON_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"FLUENZAVERBFON_ESITO\"] = \"DEFICIT\"\n",
    "            else:\n",
    "                df.loc[i,\"FLUENZAVERBFON_ESITO\"] = \"NORMA\"\n",
    "        if df.loc[i,\"FLUENZAVERBFON_PG\"] == df.loc[i,\"FLUENZAVERBFON_PG\"]:\n",
    "            if df.loc[i,\"FLUENZAVERBFON_PG\"] < const.const_dict[\"FLUENZAVERBFON_CUTOFF\"] + const.const_dict[\"FLUENZAVERBFON_CUTOFF\"]*perc and df.loc[i,\"FLUENZAVERBFON_PG\"] > const.const_dict[\"FLUENZAVERBFON_CUTOFF\"] - const.const_dict[\"FLUENZAVERBFON_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"FLUENZAVERBFON_ESITO\"] = \"LIMITI\"\n",
    "            elif df.loc[i,\"FLUENZAVERBFON_PG\"] < const.const_dict[\"FLUENZAVERBFON_CUTOFF\"] - const.const_dict[\"FLUENZAVERBFON_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"FLUENZAVERBFON_ESITO\"] = \"DEFICIT\"\n",
    "            else:\n",
    "                df.loc[i,\"FLUENZAVERBFON_ESITO\"] = \"NORMA\"\n",
    "        \n",
    "        \n",
    "        if df.loc[i,\"TESTMATRICIATTENTIVE_PC\"] == df.loc[i,\"TESTMATRICIATTENTIVE_PC\"]:\n",
    "            if df.loc[i,\"TESTMATRICIATTENTIVE_PC\"] < const.const_dict[\"TESTMATRICIATTENTIVE_CUTOFF\"] + const.const_dict[\"TESTMATRICIATTENTIVE_CUTOFF\"]*perc and df.loc[i,\"TESTMATRICIATTENTIVE_PC\"] > const.const_dict[\"TESTMATRICIATTENTIVE_CUTOFF\"] - const.const_dict[\"TESTMATRICIATTENTIVE_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"TESTMATRICIATTENTIVE_ESITO\"] = \"LIMITI\"\n",
    "            elif df.loc[i,\"TESTMATRICIATTENTIVE_PC\"] < const.const_dict[\"TESTMATRICIATTENTIVE_CUTOFF\"] - const.const_dict[\"TESTMATRICIATTENTIVE_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"TESTMATRICIATTENTIVE_ESITO\"] = \"DEFICIT\"\n",
    "            else:\n",
    "                df.loc[i,\"TESTMATRICIATTENTIVE_ESITO\"] = \"NORMA\"\n",
    "        if df.loc[i,\"TESTMATRICIATTENTIVE_PG\"] == df.loc[i,\"TESTMATRICIATTENTIVE_PG\"]:\n",
    "            if df.loc[i,\"TESTMATRICIATTENTIVE_PG\"] < const.const_dict[\"TESTMATRICIATTENTIVE_CUTOFF\"] + const.const_dict[\"TESTMATRICIATTENTIVE_CUTOFF\"]*perc and df.loc[i,\"TESTMATRICIATTENTIVE_PG\"] > const.const_dict[\"TESTMATRICIATTENTIVE_CUTOFF\"] - const.const_dict[\"TESTMATRICIATTENTIVE_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"TESTMATRICIATTENTIVE_ESITO\"] = \"LIMITI\"\n",
    "            elif df.loc[i,\"TESTMATRICIATTENTIVE_PG\"] < const.const_dict[\"TESTMATRICIATTENTIVE_CUTOFF\"] - const.const_dict[\"TESTMATRICIATTENTIVE_CUTOFF\"]*perc:\n",
    "                df.loc[i,\"TESTMATRICIATTENTIVE_ESITO\"] = \"DEFICIT\"\n",
    "            else:\n",
    "                df.loc[i,\"TESTMATRICIATTENTIVE_ESITO\"] = \"NORMA\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "_4usqhnryC1B",
    "outputId": "c7ab240c-2069-4faa-e00e-4ea95de1daa5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Scolarita</th>\n",
       "      <th>Eta</th>\n",
       "      <th>Sesso</th>\n",
       "      <th>MMSE_PG</th>\n",
       "      <th>MMSE_PC</th>\n",
       "      <th>MMSE_PE</th>\n",
       "      <th>MMSE_ESITO</th>\n",
       "      <th>CLOCKTEST_PG</th>\n",
       "      <th>CLOCKTEST_PE</th>\n",
       "      <th>...</th>\n",
       "      <th>FAB_ESITO</th>\n",
       "      <th>FLUENZAVERBFON_PG</th>\n",
       "      <th>FLUENZAVERBFON_PC</th>\n",
       "      <th>FLUENZAVERBFON_PE</th>\n",
       "      <th>FLUENZAVERBFON_ESITO</th>\n",
       "      <th>TESTMATRICIATTENTIVE_PG</th>\n",
       "      <th>TESTMATRICIATTENTIVE_PC</th>\n",
       "      <th>TESTMATRICIATTENTIVE_PE</th>\n",
       "      <th>TESTMATRICIATTENTIVE_ESITO</th>\n",
       "      <th>Patologia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Row0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>F</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.49</td>\n",
       "      <td>238.0</td>\n",
       "      <td>NORMA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NORMA</td>\n",
       "      <td>47.0</td>\n",
       "      <td>45.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NORMA</td>\n",
       "      <td>Malattia di Alzheimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Row1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>M</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28.20</td>\n",
       "      <td>238.0</td>\n",
       "      <td>NORMA</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>34.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NORMA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Assenza di patologia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Row2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>F</td>\n",
       "      <td>27.0</td>\n",
       "      <td>26.86</td>\n",
       "      <td>238.0</td>\n",
       "      <td>NORMA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>27.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NORMA</td>\n",
       "      <td>45.0</td>\n",
       "      <td>47.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NORMA</td>\n",
       "      <td>Malattia di Alzheimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Row3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>M</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.53</td>\n",
       "      <td>238.0</td>\n",
       "      <td>DEFICIT</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>DEFICIT</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DEFICIT</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DEFICIT</td>\n",
       "      <td>Malattia di Alzheimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Row4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>M</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>238.0</td>\n",
       "      <td>LIMITI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>DEFICIT</td>\n",
       "      <td>11.0</td>\n",
       "      <td>21.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>DEFICIT</td>\n",
       "      <td>37.0</td>\n",
       "      <td>41.75</td>\n",
       "      <td>2.0</td>\n",
       "      <td>LIMITI</td>\n",
       "      <td>Malattia di Alzheimer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  Scolarita   Eta Sesso  MMSE_PG  MMSE_PC  MMSE_PE MMSE_ESITO  \\\n",
       "0  Row0       13.0  65.0     F     29.0    28.49    238.0      NORMA   \n",
       "1  Row1        8.0  70.0     M     27.0    28.20    238.0      NORMA   \n",
       "2  Row2       12.0  70.0     F     27.0    26.86    238.0      NORMA   \n",
       "3  Row3        8.0  66.0     M     17.0    17.53    238.0    DEFICIT   \n",
       "4  Row4        7.0  82.0     M     25.0    25.00    238.0     LIMITI   \n",
       "\n",
       "   CLOCKTEST_PG  CLOCKTEST_PE  ... FAB_ESITO  FLUENZAVERBFON_PG  \\\n",
       "0           5.0           7.0  ...       NaN               24.0   \n",
       "1           6.0           5.0  ...       NaN               31.0   \n",
       "2           NaN           7.0  ...       NaN               24.0   \n",
       "3           2.0           5.0  ...   DEFICIT                4.0   \n",
       "4           1.0           3.0  ...   DEFICIT               11.0   \n",
       "\n",
       "   FLUENZAVERBFON_PC  FLUENZAVERBFON_PE FLUENZAVERBFON_ESITO  \\\n",
       "0               20.9                1.0                NORMA   \n",
       "1               34.9                4.0                NORMA   \n",
       "2               27.9                3.0                NORMA   \n",
       "3                7.2                0.0              DEFICIT   \n",
       "4               21.4                2.0              DEFICIT   \n",
       "\n",
       "   TESTMATRICIATTENTIVE_PG  TESTMATRICIATTENTIVE_PC  TESTMATRICIATTENTIVE_PE  \\\n",
       "0                     47.0                    45.75                      3.0   \n",
       "1                      NaN                      NaN                      NaN   \n",
       "2                     45.0                    47.00                      3.0   \n",
       "3                      7.0                     5.25                      0.0   \n",
       "4                     37.0                    41.75                      2.0   \n",
       "\n",
       "  TESTMATRICIATTENTIVE_ESITO              Patologia  \n",
       "0                      NORMA  Malattia di Alzheimer  \n",
       "1                        NaN   Assenza di patologia  \n",
       "2                      NORMA  Malattia di Alzheimer  \n",
       "3                    DEFICIT  Malattia di Alzheimer  \n",
       "4                     LIMITI  Malattia di Alzheimer  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_excel('TrainingSet.xlsx')\n",
    "df_test = pd.read_excel('TestSet.xlsx')\n",
    "\n",
    "# Convert Sex attribute in UpperCase\n",
    "df['Sesso'] = df['Sesso'].str.upper()\n",
    "\n",
    "# Remove CAP attribute\n",
    "df = df.drop(columns =['CAP'])\n",
    "df_test = df_test.drop(columns =['CAP'])\n",
    "# df = df.drop(columns =['Sesso'])\n",
    "# df = df.drop(columns =['ID'])\n",
    "\n",
    "# Remove unlabeled instances\n",
    "df = df.loc[df[\"Patologia\"] == df[\"Patologia\"]]\n",
    "\n",
    "#Correct Esito columns\n",
    "corr_esito(df)\n",
    "\n",
    "dim = df.shape[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gs1SGns7yC1Y"
   },
   "source": [
    "## Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hIBybzUFyC1Z"
   },
   "outputs": [],
   "source": [
    "# Imputation\n",
    "num_col = [c for c in df.columns if not(\"_esito\" in c.lower()) and not(\"_pe\" in c.lower()) \n",
    "           and not(\"patologia\" in c.lower()) and not(\"sesso\" in c.lower()) and not(\"id\" in c.lower())]\n",
    "enum_col = [c for c in df.columns if(\"_esito\" in c.lower()) or (\"sesso\" in c.lower())]\n",
    "\n",
    "df_imp_num = df.loc[:,num_col]\n",
    "df_imp_enum = df.loc[:,enum_col]\n",
    "\n",
    "columns = df_imp_num.columns.append(df_imp_enum.columns).insert(0, \"ID\")\n",
    "\n",
    "num_imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "# num_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value = 0)\n",
    "\n",
    "num_imputer.fit(df_imp_num.values)\n",
    "df_imp_num = pd.DataFrame(num_imputer.transform(df_imp_num.values))\n",
    "\n",
    "enum_imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "enum_imputer.fit(df_imp_enum.values)\n",
    "df_imp_enum = pd.DataFrame(enum_imputer.transform(df_imp_enum.values))\n",
    "\n",
    "df_imp_num.insert(0, \"ID\", df[\"ID\"])\n",
    "\n",
    "df_imp_enum.insert(0, \"ID\", df[\"ID\"])\n",
    "# df_imp_num\n",
    "\n",
    "# df_imp_num.append(df_imp_enum, axis = 1)\n",
    "\n",
    "result = pd.merge(df_imp_num, df_imp_enum, on = \"ID\")\n",
    "result.columns = columns\n",
    "result[\"Patologia\"] = df[\"Patologia\"]\n",
    "result\n",
    "\n",
    "# Test set imputation\n",
    "num_col = [c for c in df_test.columns if not(\"_esito\" in c.lower()) and not(\"_pe\" in c.lower()) \n",
    "           and not(\"sesso\" in c.lower()) and not(\"id\" in c.lower())]\n",
    "enum_col = [c for c in df_test.columns if(\"_esito\" in c.lower()) or (\"sesso\" in c.lower())]\n",
    "\n",
    "df_imp_num = df_test.loc[:,num_col]\n",
    "df_imp_enum = df_test.loc[:,enum_col]\n",
    "\n",
    "df_imp_num = pd.DataFrame(num_imputer.transform(df_imp_num.values))\n",
    "df_imp_enum = pd.DataFrame(enum_imputer.transform(df_imp_enum.values))\n",
    "\n",
    "df_imp_num.insert(0, \"ID\", df_test[\"ID\"])\n",
    "df_imp_enum.insert(0, \"ID\", df_test[\"ID\"])\n",
    "\n",
    "result_test = pd.merge(df_imp_num, df_imp_enum, on = \"ID\")\n",
    "result_test.columns = columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDvbq29fyC1h"
   },
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "PZ1SH195yC1i",
    "outputId": "a8e891f0-4b04-4585-b124-041799432b76"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scolarita</th>\n",
       "      <th>Eta</th>\n",
       "      <th>MMSE_PG</th>\n",
       "      <th>MMSE_PC</th>\n",
       "      <th>CLOCKTEST_PG</th>\n",
       "      <th>COPIAFIGURAREY_PG</th>\n",
       "      <th>COPIAFIGURAREY_PC</th>\n",
       "      <th>PAROLEREYIMM_PG</th>\n",
       "      <th>PAROLEREYIMM_PC</th>\n",
       "      <th>PAROLEREYDIFF_PG</th>\n",
       "      <th>...</th>\n",
       "      <th>Sesso</th>\n",
       "      <th>MMSE_ESITO</th>\n",
       "      <th>CLOCKTEST_ESITO</th>\n",
       "      <th>COPIAFIGURAREY_ESITO</th>\n",
       "      <th>PAROLEREYIMM_ESITO</th>\n",
       "      <th>PAROLEREYDIFF_ESITO</th>\n",
       "      <th>MEMORIAFIGURAREY_ESITO</th>\n",
       "      <th>FAB_ESITO</th>\n",
       "      <th>FLUENZAVERBFON_ESITO</th>\n",
       "      <th>TESTMATRICIATTENTIVE_ESITO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.49</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.75</td>\n",
       "      <td>28.0</td>\n",
       "      <td>29.3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28.20</td>\n",
       "      <td>6.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>36.00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33.9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>26.86</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>18.50</td>\n",
       "      <td>21.0</td>\n",
       "      <td>26.9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.53</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.75</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>5.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>31.03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>30.75</td>\n",
       "      <td>25.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>14.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>26.31</td>\n",
       "      <td>10.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>33.75</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>13.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>28.99</td>\n",
       "      <td>10.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>34.25</td>\n",
       "      <td>35.0</td>\n",
       "      <td>31.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>5.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>29.27</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>33.00</td>\n",
       "      <td>40.0</td>\n",
       "      <td>46.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>8.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28.20</td>\n",
       "      <td>8.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>37.00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Scolarita   Eta  MMSE_PG  MMSE_PC  CLOCKTEST_PG  COPIAFIGURAREY_PG  \\\n",
       "0         13.0  65.0     29.0    28.49           5.0               34.0   \n",
       "1          8.0  70.0     27.0    28.20           6.0               34.0   \n",
       "2         12.0  70.0     27.0    26.86           8.0               31.0   \n",
       "3          8.0  66.0     17.0    17.53           2.0                2.0   \n",
       "4          7.0  82.0     25.0    25.00           1.0               15.0   \n",
       "..         ...   ...      ...      ...           ...                ...   \n",
       "326        5.0  76.0     29.0    31.03           5.0               28.0   \n",
       "327       14.0  54.0     28.0    26.31          10.0               35.0   \n",
       "328       13.0  53.0     30.0    28.99          10.0               35.0   \n",
       "329        5.0  67.0     28.0    29.27           8.0               31.0   \n",
       "330        8.0  72.0     27.0    28.20           8.0               35.0   \n",
       "\n",
       "     COPIAFIGURAREY_PC  PAROLEREYIMM_PG  PAROLEREYIMM_PC  PAROLEREYDIFF_PG  \\\n",
       "0                34.75             28.0             29.3               8.0   \n",
       "1                36.00             28.0             33.9               6.0   \n",
       "2                18.50             21.0             26.9               6.0   \n",
       "3                 3.50             12.0             16.0               0.0   \n",
       "4                17.75             18.0             30.2               3.0   \n",
       "..                 ...              ...              ...               ...   \n",
       "326              30.75             25.0             35.0               1.0   \n",
       "327              33.75             19.0             15.5               4.0   \n",
       "328              34.25             35.0             31.5               6.0   \n",
       "329              33.00             40.0             46.1               7.0   \n",
       "330              37.00             28.0             33.9               5.0   \n",
       "\n",
       "     ...  Sesso  MMSE_ESITO  CLOCKTEST_ESITO  COPIAFIGURAREY_ESITO  \\\n",
       "0    ...    0.0         2.0              0.0                   2.0   \n",
       "1    ...    1.0         2.0              2.0                   2.0   \n",
       "2    ...    0.0         2.0              0.0                   0.0   \n",
       "3    ...    1.0         0.0              0.0                   0.0   \n",
       "4    ...    1.0         1.0              0.0                   0.0   \n",
       "..   ...    ...         ...              ...                   ...   \n",
       "326  ...    1.0         2.0              2.0                   1.0   \n",
       "327  ...    0.0         2.0              2.0                   2.0   \n",
       "328  ...    1.0         2.0              2.0                   2.0   \n",
       "329  ...    0.0         2.0              2.0                   2.0   \n",
       "330  ...    0.0         2.0              2.0                   2.0   \n",
       "\n",
       "     PAROLEREYIMM_ESITO  PAROLEREYDIFF_ESITO  MEMORIAFIGURAREY_ESITO  \\\n",
       "0                   1.0                  2.0                     1.0   \n",
       "1                   1.0                  2.0                     3.0   \n",
       "2                   0.0                  2.0                     1.0   \n",
       "3                   0.0                  0.0                     1.0   \n",
       "4                   0.0                  0.0                     1.0   \n",
       "..                  ...                  ...                     ...   \n",
       "326                 0.0                  0.0                     3.0   \n",
       "327                 0.0                  0.0                     3.0   \n",
       "328                 2.0                  2.0                     3.0   \n",
       "329                 2.0                  2.0                     3.0   \n",
       "330                 1.0                  1.0                     3.0   \n",
       "\n",
       "     FAB_ESITO  FLUENZAVERBFON_ESITO  TESTMATRICIATTENTIVE_ESITO  \n",
       "0          2.0                   2.0                         2.0  \n",
       "1          2.0                   2.0                         2.0  \n",
       "2          2.0                   2.0                         2.0  \n",
       "3          0.0                   0.0                         0.0  \n",
       "4          0.0                   0.0                         1.0  \n",
       "..         ...                   ...                         ...  \n",
       "326        0.0                   0.0                         2.0  \n",
       "327        2.0                   2.0                         2.0  \n",
       "328        2.0                   2.0                         2.0  \n",
       "329        2.0                   2.0                         2.0  \n",
       "330        2.0                   2.0                         2.0  \n",
       "\n",
       "[331 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting Training data and prediction\n",
    "num_col = [c for c in df.columns if not(\"_esito\" in c.lower()) and not(\"_pe\" in c.lower()) \n",
    "           and not(\"patologia\" in c.lower()) and not(\"sesso\" in c.lower()) and not(\"id\" in c.lower())]\n",
    "nom_col = [c for c in df.columns if(\"_esito\" in c.lower() or \"sesso\" in c.lower())]\n",
    "\n",
    "df_data_num = result[num_col]\n",
    "df_data_nom = result[nom_col]\n",
    "df_data_num_nom = result.drop([\"ID\", \"Patologia\"], axis = 1)\n",
    "df_target = result['Patologia']\n",
    "\n",
    "# Encode nominal columns\n",
    "df_data_nom = result[nom_col]\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "\n",
    "arr_enc = np.zeros((df_data_nom.shape[1], df_data_nom.shape[0]))\n",
    "i = 0\n",
    "for col in df_data_nom.columns:\n",
    "    label_enc.fit(df_data_nom[col])\n",
    "    arr_enc[i] = label_enc.transform(df_data_nom[col])\n",
    "    i = i+1\n",
    "arr_enc = arr_enc.T\n",
    "\n",
    "df_data_nom_enc = pd.DataFrame(data = arr_enc, columns = df_data_nom.columns)\n",
    "n_col = [c for c in result.columns if \"esito\" in c.lower()]\n",
    "df_data_num_nom.drop(n_col, axis=1)\n",
    "\n",
    "for c in df_data_nom_enc.columns:\n",
    "    df_data_num_nom[c] = df_data_nom_enc[c]\n",
    "\n",
    "df_data_nom = df_data_nom_enc\n",
    "\n",
    "\n",
    "# Splitting Test Set data\n",
    "num_col = [c for c in df_test.columns if not(\"_esito\" in c.lower()) and not(\"_pe\" in c.lower()) \n",
    "           and not(\"sesso\" in c.lower()) and not(\"id\" in c.lower())]\n",
    "nom_col = [c for c in df_test.columns if(\"_esito\" in c.lower()) or (\"sesso\" in c.lower())]\n",
    "\n",
    "df_data_test_num = result_test[num_col]\n",
    "df_data_test_nom = result_test[nom_col]\n",
    "df_data_test_num_nom = result_test.drop([\"ID\"], axis = 1)\n",
    "\n",
    "\n",
    "df_data_num_nom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPIgEfQrKbIT"
   },
   "source": [
    "## Decision Tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "avf0vAcnKjB1",
    "outputId": "06b6cce4-b20b-4e86-cf83-ca219bec49e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   24.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.613062004114017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   22.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6375991771965912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   21.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6405377607992948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   23.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.643696738172201\n",
      "0.6496841022627093\n",
      "Mean score:  0.6369159565089626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   21.8s finished\n"
     ]
    }
   ],
   "source": [
    "# Set up possible values of parameters to optimize over\n",
    "p_grid = {\"criterion\": [\"gini\",\"entropy\"],\n",
    "          \"min_samples_split\": np.arange(2,20,1),\n",
    "          \"min_samples_leaf\": np.arange(2,20,1)}\n",
    "\n",
    "weights = {\"Assenza di patologia\" : 1,\n",
    "           \"Malattia di Alzheimer\" : 1,\n",
    "           \"Disturbo cognitivo lieve\" : 1,\n",
    "           \"Disturbo depressivo\" : 1}\n",
    "\n",
    "# Logistic Regression Classifier\n",
    "model = DecisionTreeClassifier(splitter='best', min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None,\n",
    "                               min_impurity_decrease=0.0, min_impurity_split=None, class_weight=weights, ccp_alpha=0.0)\n",
    "\n",
    "# Number of random trials\n",
    "NUM_TRIALS = 5\n",
    "\n",
    "# Arrays to store scores\n",
    "non_nested_scores = np.zeros(NUM_TRIALS)\n",
    "nested_scores = np.zeros(NUM_TRIALS)\n",
    "\n",
    "# Model selection\n",
    "for i in range(NUM_TRIALS):\n",
    "    \n",
    "    # Choose cross-validation techniques for the inner and outer loops\n",
    "    inner_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=i)\n",
    "    outer_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=i)\n",
    "\n",
    "    # Non_nested parameter search and scoring\n",
    "    clf = GridSearchCV(estimator=model, param_grid=p_grid, cv=inner_cv, scoring = 'accuracy', verbose = 0)\n",
    "\n",
    "    # Nested CV with parameter optimization\n",
    "    nested_score = cross_val_score(clf, X=df_data_num.values, y=df_target.values, cv=outer_cv, verbose = 1)\n",
    "    print(nested_score.mean())\n",
    "    nested_scores[i] = nested_score.mean()\n",
    "    \n",
    "print(\"Mean score: \", nested_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "syxoPkipyC12"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "R3Ja73YvyC13",
    "outputId": "72a7ab03-b9a8-436d-c3ab-757bbf1e3fda"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   12.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6767190714075816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   12.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6767190714075816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   11.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6797678518953865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   12.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.679841316485454\n",
      "0.6765721422274464\n",
      "Mean score:  0.6779238906846901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   11.5s finished\n"
     ]
    }
   ],
   "source": [
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df_data_num)\n",
    "df_data_num_norm = scaler.transform(df_data_num)\n",
    "df_data_num_norm = pd.DataFrame(data = df_data_num_norm, columns = df_data_num.columns)\n",
    "\n",
    "# Set up possible values of parameters to optimize over\n",
    "p_grid = {\"C\": np.arange(0.1,2,0.3),\n",
    "          \"solver\": [\"lbfgs\", \"newton-cg\",],\n",
    "          \"multi_class\": [\"ovr\", \"multinomial\"]}\n",
    "\n",
    "weights = {\"Assenza di patologia\" : 1,\n",
    "           \"Malattia di Alzheimer\" : 1,\n",
    "           \"Disturbo cognitivo lieve\" : 2,\n",
    "           \"Disturbo depressivo\" : 3}\n",
    "\n",
    "# Logistic Regression Classifier\n",
    "model = LogisticRegression(penalty='l2', tol=0.0001, fit_intercept=True, intercept_scaling=1, \n",
    "                           class_weight= weights, random_state=None, max_iter=1000, verbose=0, l1_ratio=None)\n",
    "\n",
    "# Number of random trials\n",
    "NUM_TRIALS = 5\n",
    "\n",
    "# Arrays to store scores\n",
    "non_nested_scores = np.zeros(NUM_TRIALS)\n",
    "nested_scores = np.zeros(NUM_TRIALS)\n",
    "\n",
    "# Model selection\n",
    "for i in range(NUM_TRIALS):\n",
    "    \n",
    "    # Choose cross-validation techniques for the inner and outer loops\n",
    "    inner_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=i)\n",
    "    outer_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=i)\n",
    "\n",
    "    # Non_nested parameter search and scoring\n",
    "    clf = GridSearchCV(estimator=model, param_grid=p_grid, cv=inner_cv, scoring = 'accuracy', verbose = 0)\n",
    "\n",
    "    # Nested CV with parameter optimization\n",
    "    nested_score = cross_val_score(clf, X=df_data_num_norm.values, y=df_target.values, cv=outer_cv, verbose = 1)\n",
    "    print(nested_score.mean())\n",
    "    nested_scores[i] = nested_score.mean()\n",
    "    \n",
    "print(\"Mean score: \", nested_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-vE2ZaWyC1s"
   },
   "source": [
    "## Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7wbBTOzyC1t",
    "outputId": "52f46ff1-2134-4ebc-f6b0-5fe6595f700c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   38.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6827431677931237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   34.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6194166911548634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   35.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6313179547458125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   42.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6375257126065237\n",
      "0.66169556273876\n",
      "Mean score:  0.6465398178078167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   40.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df_data_num)\n",
    "df_data_num_norm = scaler.transform(df_data_num)\n",
    "df_data_num_norm = pd.DataFrame(data = df_data_num_norm, columns = df_data_num.columns)\n",
    "\n",
    "# Set up possible values of parameters to optimize over\n",
    "p_grid = {\"alpha\": np.arange(0.01,1,0.1),\n",
    "          \"hidden_layer_sizes\": [(19, ), (23, ), (11, )],\n",
    "          # \"momentum\": np.arange(0.1,1,0.1),\n",
    "          \"activation\": [\"logistic\", \"identity\", \"tanh\", \"relu\"]}\n",
    "\n",
    "# Multi Layer Perceptron Classifier\n",
    "model = MLPClassifier(solver='adam', learning_rate='adaptive', learning_rate_init=0.1, max_iter=1500, shuffle=True,\n",
    "                      tol=0.001, verbose=0, nesterovs_momentum=False, early_stopping=True)\n",
    "\n",
    "# Number of random trials\n",
    "NUM_TRIALS = 5\n",
    "\n",
    "# Arrays to store scores\n",
    "non_nested_scores = np.zeros(NUM_TRIALS)\n",
    "nested_scores = np.zeros(NUM_TRIALS)\n",
    "\n",
    "# Model selection\n",
    "for i in range(NUM_TRIALS):\n",
    "    \n",
    "    # Choose cross-validation techniques for the inner and outer loops\n",
    "    inner_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=i)\n",
    "    outer_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=i)\n",
    "\n",
    "    # Non_nested parameter search and scoring\n",
    "    clf = GridSearchCV(estimator=model, param_grid=p_grid, cv=inner_cv, scoring = 'accuracy', verbose = 0)\n",
    "\n",
    "    # Nested CV with parameter optimization\n",
    "    nested_score = cross_val_score(clf, X=df_data_num_norm.values, y=df_target.values, cv=outer_cv, verbose = 1)\n",
    "    print(nested_score.mean())\n",
    "    nested_scores[i] = nested_score.mean()\n",
    "    \n",
    "print(\"Mean score: \", nested_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YdvDw4eayC2A"
   },
   "source": [
    "## KNN numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jPB-dq5XyC2B",
    "outputId": "baf4bd86-d43a-48af-a62f-ed9dfde3374d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   10.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7159124302086395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    8.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7008154569497502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    9.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7219732588892154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    8.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6795841904202174\n",
      "0.7008154569497502\n",
      "Mean score:  0.7038201586835147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    8.3s finished\n"
     ]
    }
   ],
   "source": [
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df_data_num)\n",
    "df_data_num_norm = scaler.transform(df_data_num)\n",
    "df_data_num_norm = pd.DataFrame(data = df_data_num_norm, columns = df_data_num.columns)\n",
    "\n",
    "# Set up possible values of parameters to optimize over\n",
    "p_grid = {\"metric\": [\"manhattan\", \"euclidean\"],\n",
    "          \"n_neighbors\": np.arange(1,20,1),\n",
    "          \"weights\": [\"distance\", \"uniform\"]}\n",
    "\n",
    "# KNN Classifier\n",
    "# model = NearestNeighbors(*, n_neighbors=5, radius=1.0, algorithm='auto', leaf_size=30, metric='minkowski', p=2, metric_params=None, n_jobs=None)\n",
    "model = KNeighborsClassifier(radius=1.0, algorithm='auto', leaf_size=30, n_jobs=2)\n",
    "\n",
    "\n",
    "# Number of random trials\n",
    "NUM_TRIALS = 5\n",
    "\n",
    "# Arrays to store scores\n",
    "non_nested_scores = np.zeros(NUM_TRIALS)\n",
    "nested_scores = np.zeros(NUM_TRIALS)\n",
    "\n",
    "# Model selection\n",
    "for i in range(NUM_TRIALS):\n",
    "    \n",
    "    # Choose cross-validation techniques for the inner and outer loops\n",
    "    inner_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=i)\n",
    "    outer_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=i)\n",
    "\n",
    "    # Non_nested parameter search and scoring\n",
    "    clf = GridSearchCV(estimator=model, param_grid=p_grid, cv=inner_cv, scoring = 'accuracy', verbose = 0)\n",
    "\n",
    "    # Nested CV with parameter optimization\n",
    "    nested_score = cross_val_score(clf, X=df_data_num_norm.values, y=df_target.values, cv=outer_cv, verbose = 1)\n",
    "    print(nested_score.mean())\n",
    "    nested_scores[i] = nested_score.mean()\n",
    "    \n",
    "print(\"Mean score: \", nested_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN nominal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    8.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6766088745224802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    8.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.664707610931531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    7.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6706582427270056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    7.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6497942991478107\n",
      "0.6766823391125477\n",
      "Mean score:  0.6676902732882751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    8.1s finished\n"
     ]
    }
   ],
   "source": [
    "# Set up possible values of parameters to optimize over\n",
    "p_grid = {\"metric\": [\"manhattan\", \"euclidean\"],\n",
    "          \"n_neighbors\": np.arange(1,20,1),\n",
    "          \"weights\": [\"distance\", \"uniform\"]}\n",
    "\n",
    "# KNN Classifier\n",
    "# model = NearestNeighbors(*, n_neighbors=5, radius=1.0, algorithm='auto', leaf_size=30, metric='minkowski', p=2, metric_params=None, n_jobs=None)\n",
    "model = KNeighborsClassifier(radius=1.0, algorithm='auto', leaf_size=30, n_jobs=2)\n",
    "\n",
    "\n",
    "# Number of random trials\n",
    "NUM_TRIALS = 5\n",
    "\n",
    "# Arrays to store scores\n",
    "non_nested_scores = np.zeros(NUM_TRIALS)\n",
    "nested_scores = np.zeros(NUM_TRIALS)\n",
    "\n",
    "# # PROVE\n",
    "# k = [c for c in df_data_num_nom.columns if \"sesso\" not in c.lower() and \"scolarita\" not in c.lower() \n",
    "#                                         and \"eta\" not in c.lower() and \"_pg\" not in c.lower()]\n",
    "# df_data_num_nom_PROVA = df_data_num_nom[k]\n",
    "\n",
    "# Model selection\n",
    "for i in range(NUM_TRIALS):\n",
    "    \n",
    "    # Choose cross-validation techniques for the inner and outer loops\n",
    "    inner_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=i)\n",
    "    outer_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=i)\n",
    "\n",
    "    # Non_nested parameter search and scoring\n",
    "    clf = GridSearchCV(estimator=model, param_grid=p_grid, cv=inner_cv, scoring = 'accuracy', verbose = 0)\n",
    "\n",
    "    # Nested CV with parameter optimization\n",
    "    nested_score = cross_val_score(clf, X=df_data_nom.values, y=df_target.values, cv=outer_cv, verbose = 1)\n",
    "    print(nested_score.mean())\n",
    "    nested_scores[i] = nested_score.mean()\n",
    "    \n",
    "print(\"Mean score: \", nested_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPRLzqmwyC2H"
   },
   "source": [
    "## SVC with rbf kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "mVj9YZzDyC2K",
    "outputId": "f989de20-67b4-47d1-bdd4-34d1d59db267"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   11.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6978768733470466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   11.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6767558037026155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   11.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6919262415515721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   11.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6949750220393769\n",
      "0.6948280928592419\n",
      "Mean score:  0.6912724066999706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   11.2s finished\n"
     ]
    }
   ],
   "source": [
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df_data_num)\n",
    "df_data_num_norm = scaler.transform(df_data_num)\n",
    "df_data_num_norm = pd.DataFrame(data = df_data_num_norm, columns = df_data_num.columns)\n",
    "\n",
    "# Set up possible values of parameters to optimize over\n",
    "p_grid = {\"C\": np.arange(0.1,2,0.3),\n",
    "          \"gamma\": np.arange(0.01,1,0.1),\n",
    "          \"degree\":[1,2,3]}\n",
    "\n",
    "# We will use a Support Vector Classifier\n",
    "model = SVC(kernel=\"rbf\")\n",
    "\n",
    "# Number of random trials\n",
    "NUM_TRIALS = 5\n",
    "\n",
    "# Arrays to store scores\n",
    "non_nested_scores = np.zeros(NUM_TRIALS)\n",
    "nested_scores = np.zeros(NUM_TRIALS)\n",
    "\n",
    "# Model selection\n",
    "for i in range(NUM_TRIALS):\n",
    "    \n",
    "    # Choose cross-validation techniques for the inner and outer loops\n",
    "    inner_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=i)\n",
    "    outer_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=i)\n",
    "\n",
    "    # Non_nested parameter search and scoring\n",
    "    clf = GridSearchCV(estimator=model, param_grid=p_grid, cv=inner_cv, verbose = 0)\n",
    "\n",
    "    # Nested CV with parameter optimization\n",
    "    nested_score = cross_val_score(clf, X=df_data_num_norm.values, y=df_target.values, cv=outer_cv, verbose = 1)\n",
    "    print(nested_score.mean())\n",
    "    nested_scores[i] = nested_score.mean()\n",
    "    \n",
    "print(\"Mean score: \", nested_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5uAjRF1yC2R"
   },
   "source": [
    "## SVC with polinomial kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Ydi9WxINyC2S",
    "outputId": "c480c7cd-bef3-4b53-e9d1-a4e1905a7a41"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   10.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6948648251542757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   10.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6949382897443432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   11.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7039377020276227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   10.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.691962973846606\n",
      "0.6737070232148106\n",
      "Mean score:  0.6918821627975318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   10.9s finished\n"
     ]
    }
   ],
   "source": [
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df_data_num)\n",
    "df_data_num_norm = scaler.transform(df_data_num)\n",
    "df_data_num_norm = pd.DataFrame(data = df_data_num_norm, columns = df_data_num.columns)\n",
    "\n",
    "\n",
    "# Set up possible values of parameters to optimize over\n",
    "p_grid = {\"C\": np.arange(0.1,2,0.3),\n",
    "          \"gamma\": np.arange(0.01,1,0.1),\n",
    "          \"degree\":[1,2,3]}\n",
    "\n",
    "weights = {\"Assenza di patologia\" : 1,\n",
    "           \"Malattia di Alzheimer\" : 1,\n",
    "           \"Disturbo cognitivo lieve\" : 1,\n",
    "           \"Disturbo depressivo\" : 1.5}\n",
    "\n",
    "# We will use a Support Vector Classifier\n",
    "model = SVC(kernel=\"poly\", class_weight = None)\n",
    "\n",
    "# Number of random trials\n",
    "NUM_TRIALS = 5\n",
    "\n",
    "# Arrays to store scores\n",
    "non_nested_scores = np.zeros(NUM_TRIALS)\n",
    "nested_scores = np.zeros(NUM_TRIALS)\n",
    "\n",
    "# PROVE\n",
    "# k = [c for c in df_data_num_nom_norm.columns if \"sesso\" not in c.lower() ]\n",
    "# df_data_num_nom_norm_PROVA = df_data_num_nom_norm[k]\n",
    "\n",
    "# Model selection\n",
    "for i in range(NUM_TRIALS):\n",
    "    \n",
    "    # Choose cross-validation techniques for the inner and outer loops\n",
    "    inner_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=i)\n",
    "    outer_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=i)\n",
    "\n",
    "    # Non_nested parameter search and scoring\n",
    "    clf = GridSearchCV(estimator=model, param_grid=p_grid, cv=inner_cv, verbose = 0)\n",
    "\n",
    "    # Nested CV with parameter optimization\n",
    "    nested_score = cross_val_score(clf, X=df_data_num_norm.values, y=df_target.values, cv=outer_cv, verbose = 1)\n",
    "    print(nested_score.mean())\n",
    "    nested_scores[i] = nested_score.mean()\n",
    "    \n",
    "print(\"Mean score: \", nested_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selected models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RaQLfAgrOczt"
   },
   "source": [
    "## SVC Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Omn-G8CqyC2b"
   },
   "source": [
    "### Hyperparameter Selection SVC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 492
    },
    "id": "Z520FLZqyC2b",
    "outputId": "14e60fe7-075f-4b9f-e010-30e4d20c4a21"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 210 candidates, totalling 2100 fits\n",
      "Best score:  0.733596837944664\n",
      "Best params:  {'C': 1.9000000000000004, 'degree': 3, 'gamma': 0.21000000000000002}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2100 out of 2100 | elapsed:   13.5s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>{'C': 1.9000000000000004, 'degree': 3, 'gamma'...</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.733597</td>\n",
       "      <td>0.071310</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>{'C': 1.9000000000000004, 'degree': 2, 'gamma'...</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.733399</td>\n",
       "      <td>0.066724</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>{'C': 1.3000000000000003, 'degree': 2, 'gamma'...</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.733399</td>\n",
       "      <td>0.066724</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>{'C': 0.7000000000000001, 'degree': 2, 'gamma'...</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.733399</td>\n",
       "      <td>0.066724</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>{'C': 1.6000000000000003, 'degree': 3, 'gamma'...</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.729249</td>\n",
       "      <td>0.074262</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                params  split0_test_score  \\\n",
       "202  {'C': 1.9000000000000004, 'degree': 3, 'gamma'...           0.608696   \n",
       "195  {'C': 1.9000000000000004, 'degree': 2, 'gamma'...           0.652174   \n",
       "136  {'C': 1.3000000000000003, 'degree': 2, 'gamma'...           0.652174   \n",
       "78   {'C': 0.7000000000000001, 'degree': 2, 'gamma'...           0.652174   \n",
       "172  {'C': 1.6000000000000003, 'degree': 3, 'gamma'...           0.565217   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "202           0.727273           0.772727           0.772727   \n",
       "195           0.818182           0.818182           0.772727   \n",
       "136           0.818182           0.818182           0.772727   \n",
       "78            0.818182           0.818182           0.772727   \n",
       "172           0.727273           0.772727           0.772727   \n",
       "\n",
       "     split4_test_score  split5_test_score  split6_test_score  \\\n",
       "202           0.863636           0.681818           0.681818   \n",
       "195           0.727273           0.681818           0.636364   \n",
       "136           0.727273           0.681818           0.636364   \n",
       "78            0.727273           0.681818           0.636364   \n",
       "172           0.863636           0.727273           0.681818   \n",
       "\n",
       "     split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "202           0.681818           0.818182           0.727273         0.733597   \n",
       "195           0.681818           0.818182           0.727273         0.733399   \n",
       "136           0.681818           0.818182           0.727273         0.733399   \n",
       "78            0.681818           0.818182           0.727273         0.733399   \n",
       "172           0.681818           0.772727           0.727273         0.729249   \n",
       "\n",
       "     std_test_score  rank_test_score  \n",
       "202        0.071310                1  \n",
       "195        0.066724                2  \n",
       "136        0.066724                2  \n",
       "78         0.066724                2  \n",
       "172        0.074262                5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split dataset (2/3 training , 1/3 test)\n",
    "data_train, data_test, target_train, target_test = train_test_split(df_data_num.values, df_target.values, test_size=0.33, stratify = df_target)\n",
    "\n",
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data_train)\n",
    "\n",
    "data_train_norm = scaler.transform(data_train)\n",
    "data_train_norm = pd.DataFrame(data = data_train_norm, columns = df_data_num.columns)\n",
    "\n",
    "data_test_norm = scaler.transform(data_test)\n",
    "data_test_norm = pd.DataFrame(data = data_test_norm, columns = df_data_num.columns)\n",
    "\n",
    "# data_train_norm = minmax_scale(data_train, feature_range=(0, 1), axis=0, copy=True)\n",
    "# data_test_norm = minmax_scale(data_test, feature_range=(0, 1), axis=0, copy=True)\n",
    "\n",
    "# Select best hyerparameter\n",
    "p_grid = {\"C\": np.arange(0.1,2,0.3),\n",
    "          \"gamma\": np.arange(0.01,1,0.1),\n",
    "          \"degree\":[1,2,3]}\n",
    "\n",
    "\n",
    "weights = {\"Assenza di patologia\" : 1,\n",
    "           \"Malattia di Alzheimer\" : 1,\n",
    "           \"Disturbo cognitivo lieve\" : 1,\n",
    "           \"Disturbo depressivo\" : 1.5}\n",
    "\n",
    "model = SVC(kernel=\"poly\", class_weight = weights)\n",
    "hyp_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "clf = GridSearchCV(estimator=model, param_grid=p_grid, cv= hyp_cv, verbose = 1, scoring = 'accuracy')\n",
    "\n",
    "clf.fit(data_train_norm,target_train)\n",
    "\n",
    "print(\"Best score: \", clf.best_score_)\n",
    "print(\"Best params: \", clf.best_params_)\n",
    "\n",
    "\n",
    "df_score = pd.DataFrame(clf.cv_results_)\n",
    "df_score = df_score.sort_values(by=[\"rank_test_score\"])\n",
    "df_score = df_score.loc[:,\"params\":\"rank_test_score\"]\n",
    "df_score.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_d6aFZ6yC2m"
   },
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "id": "U4AfTch2yC2p",
    "outputId": "a3a48020-fc20-4e1d-f8e4-85e19fb5e90f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6818181818181818\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conf. matrix</th>\n",
       "      <th>Assenza di patologia</th>\n",
       "      <th>Malattia di Alzheimer</th>\n",
       "      <th>Disturbo cognitivo lieve</th>\n",
       "      <th>Disturbo depressivo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Assenza di patologia</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malattia di Alzheimer</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Disturbo cognitivo lieve</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Disturbo depressivo</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Conf. matrix  Assenza di patologia  Malattia di Alzheimer  \\\n",
       "0      Assenza di patologia                    65                      0   \n",
       "1     Malattia di Alzheimer                    10                      8   \n",
       "2  Disturbo cognitivo lieve                     3                      9   \n",
       "3       Disturbo depressivo                     5                      3   \n",
       "\n",
       "   Disturbo cognitivo lieve  Disturbo depressivo  \n",
       "0                         2                    0  \n",
       "1                         3                    0  \n",
       "2                         2                    0  \n",
       "3                         0                    0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating model on 1/3 of dataset\n",
    "weights = {\"Assenza di patologia\" : 1,\n",
    "           \"Malattia di Alzheimer\" : 1,\n",
    "           \"Disturbo cognitivo lieve\" : 1,\n",
    "           \"Disturbo depressivo\" : 1.5}\n",
    "\n",
    "model = SVC(kernel=\"poly\", C = 1,  degree = 3, gamma = 0.2, class_weight = weights)\n",
    "\n",
    "model.fit(data_train_norm, target_train)\n",
    "prediction = model.predict(data_test_norm)\n",
    "# print(\"Accuracy: \", svm.score(data_test, target_test))\n",
    "print(\"Accuracy: \", accuracy_score(target_test, prediction))\n",
    "labels = [\"Assenza di patologia\", \"Malattia di Alzheimer\",  \"Disturbo cognitivo lieve\", \"Disturbo depressivo\"]\n",
    "df_cm = pd.DataFrame(confusion_matrix(target_test, prediction, labels= labels, sample_weight=None, normalize=None), columns = labels)\n",
    "df_cm.insert(0, \"Conf. matrix\", labels)\n",
    "df_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOLe5QEIyC29"
   },
   "source": [
    "### New instances prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "FBS7oFidyC3A",
    "outputId": "ddb78fe9-5346-4c53-fc7e-21aad9d44f3b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patologia</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Assenza di patologia</th>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disturbo cognitivo lieve</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disturbo depressivo</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malattia di Alzheimer</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           ID\n",
       "Patologia                    \n",
       "Assenza di patologia      124\n",
       "Disturbo cognitivo lieve    4\n",
       "Disturbo depressivo         1\n",
       "Malattia di Alzheimer      35"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df_data_num)\n",
    "\n",
    "df_data_num_norm = scaler.transform(df_data_num)\n",
    "df_data_num_norm = pd.DataFrame(data = df_data_num_norm, columns = df_data_num.columns)\n",
    "\n",
    "df_data_test_num_norm = scaler.transform(df_data_test_num)\n",
    "df_data_test_num_norm = pd.DataFrame(data = df_data_test_num_norm, columns = df_data_test_num.columns)\n",
    "# data_norm = minmax_scale(df_data_num, feature_range=(0, 1), axis=0, copy=True)\n",
    "# data_test_num_norm = minmax_scale(df_data_test_num, feature_range=(0, 1), axis=0, copy=True)\n",
    "\n",
    "weights = {\"Assenza di patologia\" : 1,\n",
    "           \"Malattia di Alzheimer\" : 1,\n",
    "           \"Disturbo cognitivo lieve\" : 1,\n",
    "           \"Disturbo depressivo\" : 1.5}\n",
    "\n",
    "model = SVC(kernel=\"poly\", C = 1,  degree = 3, gamma = 0.2, class_weight = weights)\n",
    "\n",
    "model.fit(df_data_num_norm.values,df_target.values)\n",
    "prediction = model.predict(df_data_test_num_norm.values)\n",
    "\n",
    "df_sub = result_test[[\"ID\"]]\n",
    "df_sub.insert(len(df_sub.columns), \"Patologia\", prediction)\n",
    "\n",
    "df_sub.groupby(\"Patologia\").count().sort_values(by=\"Patologia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "IGJ-1RK-yC3L",
    "outputId": "578f28c0-9ae9-4d8e-c37b-1acddf2056f0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Patologia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Row6</td>\n",
       "      <td>Disturbo cognitivo lieve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Row8</td>\n",
       "      <td>Malattia di Alzheimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Row9</td>\n",
       "      <td>Assenza di patologia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Row10</td>\n",
       "      <td>Assenza di patologia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Row13</td>\n",
       "      <td>Malattia di Alzheimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Row505</td>\n",
       "      <td>Assenza di patologia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Row506</td>\n",
       "      <td>Malattia di Alzheimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Row507</td>\n",
       "      <td>Assenza di patologia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Row508</td>\n",
       "      <td>Assenza di patologia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Row509</td>\n",
       "      <td>Assenza di patologia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                 Patologia\n",
       "0      Row6  Disturbo cognitivo lieve\n",
       "1      Row8     Malattia di Alzheimer\n",
       "2      Row9      Assenza di patologia\n",
       "3     Row10      Assenza di patologia\n",
       "4     Row13     Malattia di Alzheimer\n",
       "..      ...                       ...\n",
       "159  Row505      Assenza di patologia\n",
       "160  Row506     Malattia di Alzheimer\n",
       "161  Row507      Assenza di patologia\n",
       "162  Row508      Assenza di patologia\n",
       "163  Row509      Assenza di patologia\n",
       "\n",
       "[164 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "cth9-XoMyC3T"
   },
   "outputs": [],
   "source": [
    "df_sub.to_csv(\"SVC_poly_1_3_0p2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0g-KXS6OJFi"
   },
   "source": [
    "## KNN Classifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8iVPoKciO_HF"
   },
   "source": [
    "### Hyperparameter Selection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 579
    },
    "id": "Tw12lUAVPH7P",
    "outputId": "08b2bda6-e46a-4e88-e55d-defe2099b636"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 76 candidates, totalling 760 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.7373517786561266\n",
      "Best params:  {'metric': 'manhattan', 'n_neighbors': 6, 'weights': 'distance'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 760 out of 760 | elapsed:    5.8s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 6, 'wei...</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.737352</td>\n",
       "      <td>0.086232</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 7, 'wei...</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.728458</td>\n",
       "      <td>0.078810</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 5, 'wei...</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.728261</td>\n",
       "      <td>0.093682</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 5, 'wei...</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.728261</td>\n",
       "      <td>0.093682</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 14, 'we...</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.724111</td>\n",
       "      <td>0.073905</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  split0_test_score  \\\n",
       "10  {'metric': 'manhattan', 'n_neighbors': 6, 'wei...           0.782609   \n",
       "12  {'metric': 'manhattan', 'n_neighbors': 7, 'wei...           0.739130   \n",
       "46  {'metric': 'euclidean', 'n_neighbors': 5, 'wei...           0.782609   \n",
       "8   {'metric': 'manhattan', 'n_neighbors': 5, 'wei...           0.782609   \n",
       "26  {'metric': 'manhattan', 'n_neighbors': 14, 'we...           0.695652   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "10           0.681818           0.818182           0.818182   \n",
       "12           0.772727           0.772727           0.818182   \n",
       "46           0.772727           0.681818           0.818182   \n",
       "8            0.636364           0.818182           0.818182   \n",
       "26           0.772727           0.818182           0.818182   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "10           0.772727           0.818182           0.727273   \n",
       "12           0.772727           0.772727           0.681818   \n",
       "46           0.727273           0.863636           0.636364   \n",
       "8            0.727273           0.818182           0.681818   \n",
       "26           0.681818           0.772727           0.772727   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "10           0.772727           0.636364           0.545455         0.737352   \n",
       "12           0.772727           0.636364           0.545455         0.728458   \n",
       "46           0.818182           0.590909           0.590909         0.728261   \n",
       "8            0.818182           0.636364           0.545455         0.728261   \n",
       "26           0.636364           0.681818           0.590909         0.724111   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "10        0.086232                1  \n",
       "12        0.078810                2  \n",
       "46        0.093682                3  \n",
       "8         0.093682                3  \n",
       "26        0.073905                5  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split dataset (2/3 training , 1/3 test)\n",
    "data_train, data_test, target_train, target_test = train_test_split(df_data_num.values, df_target.values, test_size=0.33, stratify = df_target)\n",
    "\n",
    "# Normalize data\n",
    "# data_train_norm = minmax_scale(data_train, feature_range=(0, 1), axis=0, copy=True)\n",
    "# data_test_norm = minmax_scale(data_test, feature_range=(0, 1), axis=0, copy=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data_train)\n",
    "\n",
    "data_train_norm = scaler.transform(data_train)\n",
    "data_train_norm = pd.DataFrame(data = data_train_norm, columns = df_data_num.columns)\n",
    "\n",
    "data_test_norm = scaler.transform(data_test)\n",
    "data_test_norm = pd.DataFrame(data = data_test_norm, columns = df_data_num.columns)\n",
    "\n",
    "# Select best hyerparameter\n",
    "p_grid = {\"metric\": [\"manhattan\", \"euclidean\"],\n",
    "          \"n_neighbors\": np.arange(1,20,1),\n",
    "          \"weights\": [\"distance\", \"uniform\"]}\n",
    "\n",
    "# KNN Classifier\n",
    "model = KNeighborsClassifier(radius=1.0, algorithm='auto', leaf_size=30, n_jobs=2)\n",
    "hyp_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "clf = GridSearchCV(estimator=model, param_grid=p_grid, cv= hyp_cv, verbose = 1, scoring = 'accuracy')\n",
    "\n",
    "clf.fit(data_train_norm.values,target_train)\n",
    "\n",
    "print(\"Best score: \", clf.best_score_)\n",
    "print(\"Best params: \", clf.best_params_)\n",
    "\n",
    "\n",
    "df_score = pd.DataFrame(clf.cv_results_)\n",
    "df_score = df_score.sort_values(by=[\"rank_test_score\"])\n",
    "df_score = df_score.loc[:,\"params\":\"rank_test_score\"]\n",
    "df_score.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AUhT40bFP-IE"
   },
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "id": "6tcXgIUQQEZo",
    "outputId": "aa8716d0-602d-4179-b4b2-d1f23864b020"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6545454545454545\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conf. matrix</th>\n",
       "      <th>Assenza di patologia</th>\n",
       "      <th>Malattia di Alzheimer</th>\n",
       "      <th>Disturbo cognitivo lieve</th>\n",
       "      <th>Disturbo depressivo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Assenza di patologia</td>\n",
       "      <td>61</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malattia di Alzheimer</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Disturbo cognitivo lieve</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Disturbo depressivo</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Conf. matrix  Assenza di patologia  Malattia di Alzheimer  \\\n",
       "0      Assenza di patologia                    61                      4   \n",
       "1     Malattia di Alzheimer                    12                      8   \n",
       "2  Disturbo cognitivo lieve                     6                      5   \n",
       "3       Disturbo depressivo                     6                      1   \n",
       "\n",
       "   Disturbo cognitivo lieve  Disturbo depressivo  \n",
       "0                         1                    1  \n",
       "1                         1                    0  \n",
       "2                         3                    0  \n",
       "3                         1                    0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating model on 1/3 of dataset\n",
    "model = KNeighborsClassifier(radius=1.0, algorithm='auto', leaf_size=30, n_jobs=2, metric = \"manhattan\", n_neighbors=8, weights=\"distance\")\n",
    "\n",
    "model.fit(data_train_norm, target_train)\n",
    "prediction = model.predict(data_test_norm)\n",
    "# print(\"Accuracy: \", svm.score(data_test, target_test))\n",
    "print(\"Accuracy: \", accuracy_score(target_test, prediction))\n",
    "labels = [\"Assenza di patologia\", \"Malattia di Alzheimer\",  \"Disturbo cognitivo lieve\", \"Disturbo depressivo\"]\n",
    "df_cm = pd.DataFrame(confusion_matrix(target_test, prediction, labels= labels, sample_weight=None, normalize=None), columns = labels)\n",
    "df_cm.insert(0, \"Conf. matrix\", labels)\n",
    "df_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKckuSHNRJ5a"
   },
   "source": [
    "### New instances prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "aNdrzREoRNCA",
    "outputId": "ccd6fb44-d03e-484c-9e3b-2a648e8461ad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patologia</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Assenza di patologia</th>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disturbo cognitivo lieve</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malattia di Alzheimer</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           ID\n",
       "Patologia                    \n",
       "Assenza di patologia      129\n",
       "Disturbo cognitivo lieve   12\n",
       "Malattia di Alzheimer      23"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize data\n",
    "# data_norm = minmax_scale(df_data_num, feature_range=(0, 1), axis=0, copy=True)\n",
    "# data_test_num_norm = minmax_scale(df_data_test_num, feature_range=(0, 1), axis=0, copy=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df_data_num)\n",
    "\n",
    "df_data_num_norm = scaler.transform(df_data_num)\n",
    "df_data_num_norm = pd.DataFrame(data = df_data_num_norm, columns = df_data_num.columns)\n",
    "\n",
    "df_data_test_num_norm = scaler.transform(df_data_test_num)\n",
    "df_data_test_num_norm = pd.DataFrame(data = df_data_test_num_norm, columns = df_data_test_num.columns)\n",
    "\n",
    "model = KNeighborsClassifier(radius=1.0, algorithm='auto', leaf_size=30, n_jobs=2, metric = \"manhattan\", n_neighbors=8, weights=\"uniform\")\n",
    "\n",
    "model.fit(data_norm,df_target.values)\n",
    "prediction = model.predict(df_data_test_num_norm.values)\n",
    "\n",
    "df_sub = result_test[[\"ID\"]]\n",
    "df_sub.insert(len(df_sub.columns), \"Patologia\", prediction)\n",
    "\n",
    "df_sub.groupby(\"Patologia\").count().sort_values(by=\"Patologia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "UYhqd4axSSRw",
    "outputId": "e01a6f71-fc19-4de4-8497-b371f0e5590e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Patologia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Row6</td>\n",
       "      <td>Disturbo cognitivo lieve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Row8</td>\n",
       "      <td>Assenza di patologia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Row9</td>\n",
       "      <td>Assenza di patologia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Row10</td>\n",
       "      <td>Assenza di patologia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Row13</td>\n",
       "      <td>Assenza di patologia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Row505</td>\n",
       "      <td>Assenza di patologia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Row506</td>\n",
       "      <td>Assenza di patologia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Row507</td>\n",
       "      <td>Assenza di patologia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Row508</td>\n",
       "      <td>Assenza di patologia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Row509</td>\n",
       "      <td>Assenza di patologia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                 Patologia\n",
       "0      Row6  Disturbo cognitivo lieve\n",
       "1      Row8      Assenza di patologia\n",
       "2      Row9      Assenza di patologia\n",
       "3     Row10      Assenza di patologia\n",
       "4     Row13      Assenza di patologia\n",
       "..      ...                       ...\n",
       "159  Row505      Assenza di patologia\n",
       "160  Row506      Assenza di patologia\n",
       "161  Row507      Assenza di patologia\n",
       "162  Row508      Assenza di patologia\n",
       "163  Row509      Assenza di patologia\n",
       "\n",
       "[164 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "OSFEoCrZSSoG"
   },
   "outputs": [],
   "source": [
    "df_sub.to_csv(\"KNN_manhattan_8_uniform.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ContestImputationSemplice.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc-autonumbering": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
